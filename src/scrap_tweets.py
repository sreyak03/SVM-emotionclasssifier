# -*- coding: utf-8 -*-
"""scrap_tweets.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qF5loYslXgpXatbvWaRKWOMDiIQVmjSO
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
import re
import time
import joblib
from sklearn.cluster import KMeans


# Download stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

# 1. Load dataset
df = pd.read_csv('emotions (1).csv')  # Replace with actual path

# 2. Preprocess text
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r"http\S+|@\S+|#\S+", "", text)  # Remove URLs, mentions, hashtags
    text = re.sub(r"[^a-z\s]", "", text)  # Remove punctuation and numbers
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    return " ".join(tokens)

print("Preprocessing text...")
df['clean_text'] = df['text'].apply(preprocess_text)

# 3. For kernel comparison (subset only)
small_df = df.sample(n=5000, random_state=42)

# 4. Vectorize text
vectorizer = TfidfVectorizer(max_features=1000)
X_small = vectorizer.fit_transform(small_df['clean_text'])
y_small = small_df['label']


#clustering
# Assuming X is your TF-IDF matrix (from vectorizer.fit_transform)

# Choose number of clusters (e.g., 6 for 6 emotions, or experiment)
num_clusters = 6
kmeans = KMeans(n_clusters=num_clusters, random_state=42)
clusters = kmeans.fit_predict(X_small)

# Add cluster labels to your dataframe
df_sample = df.sample(n=5000, random_state=42)
X_sample = vectorizer.transform(df_sample['clean_text'])

kmeans = KMeans(n_clusters=6, random_state=42)
clusters = kmeans.fit_predict(X_sample)

df_sample['cluster'] = clusters  # This works because lengths match

# Don't try to assign clusters to full df if clusters length != len(df)


# Optional: show number of tweets per cluster
print(df_sample['cluster'].value_counts())

# Plot cluster sizes
plt.bar(df_sample['cluster'].value_counts().index, df_sample['cluster'].value_counts().values)
plt.xlabel('Cluster')
plt.ylabel('Number of Tweets')
plt.title('Tweet Counts per Cluster')
plt.show()


# 5. Train/test split
X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_small, y_small, test_size=0.2, random_state=42, stratify=y_small)

# 6. Compare kernels (on small set)
from sklearn.svm import SVC
kernels = ['linear', 'poly', 'rbf']
print("\n--- Kernel Comparison (on 5k samples) ---")
for kernel in kernels:
    print(f"\nTraining SVM with {kernel} kernel...")
    model = LinearSVC(random_state=42, max_iter=10000) if kernel == 'linear' else SVC(kernel=kernel, random_state=42)
    start = time.time()
    model.fit(X_train_s, y_train_s)
    elapsed = time.time() - start
    y_pred = model.predict(X_test_s)
    print(f"Accuracy: {accuracy_score(y_test_s, y_pred):.4f}")
    print(f"Time taken: {elapsed:.2f} sec")
    print(classification_report(y_test_s, y_pred))
    labels = sorted(y_test_s.unique())
    cm = confusion_matrix(y_test_s, y_pred, labels=labels)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels, cmap='Blues')
    plt.title(f'Confusion Matrix - {kernel} kernel')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

# 7. Final model training on full dataset (only linear kernel)
print("\n--- Training Final Model on Full Dataset (Linear Kernel) ---")
vectorizer_full = TfidfVectorizer(max_features=5000)
X_full = vectorizer_full.fit_transform(df['clean_text'])
y_full = df['label']
X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.2, random_state=42, stratify=y_full)

final_model = LinearSVC(random_state=42, max_iter=10000)
start = time.time()
final_model.fit(X_train, y_train)
elapsed = time.time() - start
print(f"Final model trained in {elapsed:.2f} seconds")

# Evaluate
y_pred = final_model.predict(X_test)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print(classification_report(y_test, y_pred))

# Save model and vectorizer


# Save model and vectorizer
joblib.dump(final_model, 'svm_model_linear.pkl')
joblib.dump(vectorizer_full, 'tfidf_vectorizer.pkl')

print("Model and vectorizer saved.")

def check_alert(new_texts):
    X_new = vectorizer.transform(new_texts)
    clusters_new = kmeans.predict(X_new)
    # Example: alert if more than 3 texts in cluster 2 (say, negative cluster)
    if sum(clusters_new == 2) > 3:
        print("Alert: High volume of negative emotion tweets detected!")