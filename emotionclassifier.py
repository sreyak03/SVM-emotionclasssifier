# -*- coding: utf-8 -*-
"""emotionclassifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dQ0WE4zZ9Pq4dFbFddv8BNwVjgIbss_l
"""

# ðŸ“¦ Import required libraries
import pandas as pd
import numpy as np
import re
import string
import joblib
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.preprocessing import LabelEncoder

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

# ðŸ›  Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# ðŸ“¥ Load dataset
data = pd.read_csv('emotions (1).csv')  # Replace with your actual path

# ðŸš« Handle missing values and duplicates
print("Missing values before handling:")
print(data.isnull().sum())
data.dropna(inplace=True)
data.drop_duplicates(subset='text', inplace=True)

# ðŸ§¾ Show class distribution
print("\nClass distribution:")
print(data['label'].value_counts())

# âœ‚ Text preprocessing function
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r"http\S+|www\S+|https\S+", '', text)
    text = re.sub(r'\@\w+|\#','', text)
    text = re.sub(r'[^\w\s]', '', text)
    text = re.sub(r'\d+', '', text)
    text = text.strip()
    tokens = text.split()
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    stemmer = PorterStemmer()
    tokens = [stemmer.stem(word) for word in tokens]
    return ' '.join(tokens)

# ðŸ§¹ Apply preprocessing
data['cleaned_text'] = data['text'].apply(preprocess_text)

# ðŸ”¤ Encode emotion labels
label_encoder = LabelEncoder()
data['encoded_label'] = label_encoder.fit_transform(data['label'])

# ðŸ“Š Split data
X = data['cleaned_text']
y = data['encoded_label']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# âœ¨ TF-IDF Vectorization
tfidf = TfidfVectorizer(max_features=20000)
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

# ðŸ›  Optional: limit training size for speed
X_train_tfidf = X_train_tfidf[:20000]
y_train = y_train[:20000]

# ðŸ“Š Evaluate SVM with different kernels
def evaluate_svm(kernel_type):
    print(f"\nTraining and evaluating SVM with {kernel_type} kernel...")
    model = SVC(kernel=kernel_type, random_state=42)
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)

    # Convert class names to strings
    class_names = [str(cls) for cls in label_encoder.classes_]

    acc = accuracy_score(y_test, y_pred)
    report_dict = classification_report(
        y_test, y_pred, target_names=class_names, output_dict=True
    )

    print(f"\nSVM with {kernel_type} kernel:")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred, target_names=class_names))

    # ðŸ“‰ Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix - {kernel_type} kernel')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.show()

    return acc, report_dict, model

# ðŸ”„ Try multiple kernels
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
results = {}
best_model = None
best_kernel = ""
best_acc = 0

for kernel in kernels:
    accuracy, report, model = evaluate_svm(kernel)
    results[kernel] = {
        'accuracy': accuracy,
        'precision': report['weighted avg']['precision'],
        'recall': report['weighted avg']['recall'],
        'f1-score': report['weighted avg']['f1-score']
    }
    if accuracy > best_acc:
        best_acc = accuracy
        best_model = model
        best_kernel = kernel

# ðŸ“Š Kernel Performance Summary
results_df = pd.DataFrame(results).T
print("\nPerformance comparison across kernels:")
print(results_df)

plt.figure(figsize=(10, 6))
results_df.plot(kind='bar', y=['accuracy', 'precision', 'recall', 'f1-score'],
                title='SVM Kernel Performance Comparison')
plt.xticks(rotation=0)
plt.ylabel('Score')
plt.legend(loc='lower right')
plt.tight_layout()
plt.show()

print(f"\nâœ… Best performing kernel: {best_kernel}")

# ðŸ’¾ Save the best model and vectorizer
joblib.dump(best_model, 'best_svm_model.pkl')
joblib.dump(tfidf, 'tfidf_vectorizer.pkl')
joblib.dump(label_encoder, 'label_encoder.pkl')

print("\nâœ… Model, vectorizer, and label encoder saved!")